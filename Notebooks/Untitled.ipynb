{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = gpd.read_file('../Datasets/ultimate_move_df.shp')\n",
    "queen_w = Queen.from_shapefile(\"../Datasets/ultimate_move_df.shp\")\n",
    "n, bins, patches = plt.hist(queen_w.cardinalities.values(), 25, facecolor='green', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying Unusual Block Groups Based on Neighbor Counts\n",
    "\n",
    "Now that the adjacency matrix is built, we can examine some characteristics of the links formed. Below we plot a histogram of the number of neighbors. As you can see, the median number of neighbors for these units is somewhere around 50. Two oddities that we can see here are that there is one block group with 0 neighbors and one block group with 175(!) neighbors. We examine these further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Group Connectivity: Queen Adjacency Neighbors')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily identify the “island” block group by selecting for the block group with 0 neighbors. Given that this is not a typical area within Spain, we will drop it from the analysis. However, in general, areas with no neighbors could still be included in a spatial regression model, although they would receive no spatial weight and therefore would be defined as having no relationship to any other geographic units.\n",
    "\n",
    "From the histogram you can also see that there is a huge outlier - a block group that has 175 neighbors. We plot it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idmax=pd.Series(queen_w.cardinalities).idxmax()\n",
    "p=geo.loc[[idmax]].plot()\n",
    "s=p.set_xticks([])\n",
    "s=p.set_yticks([])\n",
    "title=plt.title('Area with 175 Neighbours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = gpd.read_file('../Datasets/ultimate_move_df_cleaned.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tryout = geo.copy(deep=True)\n",
    "df_tryout['tot_build_perc'] = df_tryout.srf_tot/df_tryout.shape__are\n",
    "df_tryout['housing_perc'] = df_tryout.srf_housin/df_tryout.shape__are\n",
    "\n",
    "df_tryout['shape__are'] = df_tryout.shape__are /1000000\n",
    "df_tryout['pop_per_km2'] = df_tryout.tot_pop/df_tryout.shape__are\n",
    "df_tryout['male_female_ratio'] = df_tryout.Male/df_tryout.Female\n",
    "df_tryout['young_per_km2'] = df_tryout.sub_16_age / df_tryout.shape__are\n",
    "df_tryout['middle_per_km2'] = df_tryout['16_to_64_a'] / df_tryout.shape__are\n",
    "df_tryout['old_per_km2'] = df_tryout['64_more_ag'] / df_tryout.shape__are\n",
    "df_tryout['travel_perc'] = df_tryout.pob_sale/df_tryout.tot_pop\n",
    "df_tryout['stay_home_perc'] = df_tryout.pob_casa/df_tryout.tot_pop\n",
    "\n",
    "df_tryout = df_tryout.drop(['shape_leng','shape_leng','NO2_avg_ut'\n",
    "                           ,'sub_16_age','16_to_64_a','64_more_ag','weight_urb','weight_tr','Male',\n",
    "                            'Female','srf_housin','srf_tot'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "import seaborn as sns\n",
    "mask = np.zeros_like(df_tryout.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(df_tryout.corr(), mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-afb8547a7bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNO2_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mresults_NO2_avg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO2_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "\n",
    "num_trees=100\n",
    "num_features=5\n",
    "max_depth = 5\n",
    "model=RandomForestRegressor(n_estimators=num_trees, max_features=num_features,max_depth=max_depth, random_state=seed)\n",
    "model.fit(X,NO2_avg)\n",
    "\n",
    "results_NO2_avg=cross_val_score(model, X, NO2_avg, cv=kfold)\n",
    "\n",
    "print(f'Random Forest - Accuracy {results_NO2_avg.mean()*100:.3f}% std {results_NO2_avg.std()*100:3f}%')\n",
    "\n",
    "res_w1[\"Res\"]=results_NO2_avg\n",
    "res_w1[\"Type\"]=\"Random Forest\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_NO2_avg = NO2_avg.mean()\n",
    "print(f'Average NO2 level: {mean_NO2_avg}')\n",
    "print()\n",
    "print(f'Expected error range: [{mean_NO2_avg-(1-results_NO2_avg.mean()/100)}, {mean_NO2_avg+(1-results_NO2_avg.mean()/100)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,9))\n",
    "\n",
    "for name, importance in zip(col_names, model.feature_importances_):\n",
    "    print(f'{name:15s}  {importance:.4f}')\n",
    "\n",
    "sns.barplot(x=col_names, y=model.feature_importances_, order=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tryout['less45m2_per_km2'] = (df_tryout['less_30_m2'] + df_tryout['30_45_m2'])/df_tryout.shape__are\n",
    "df_tryout['46m2_50m2_per_km2']=df_tryout['46_60_m2']/df_tryout.shape__are\n",
    "df_tryout['61m2_90m2_per_km2'] = (df_tryout['61_75_m2'] + df_tryout['76_90_m2'] )/df_tryout.shape__are\n",
    "df_tryout['more90m2_per_km2'] = ( df_tryout['91_105_m2']+df_tryout['106_120_m2'] +  df_tryout['121_150_m2'] + df_tryout['150_180_m2'] + df_tryout['above_180_'])/df_tryout.shape__are\n",
    "\n",
    "\n",
    "df_tryout = df_tryout.drop(['less_30_m2' ,'30_45_m2','46_60_m2', '61_75_m2','76_90_m2','91_105_m2','106_120_m2','121_150_m2','150_180_m2',\n",
    "                            'above_180_','first_home', 'pop_per_km2','tot_house','stay_home_perc','pob_casa','male_female_ratio','second_hom','vacation_h'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,9))\n",
    "\n",
    "for name, importance in zip(col_names, model.feature_importances_):\n",
    "    print(f'{name:15s}  {importance:.4f}')\n",
    "\n",
    "sns.barplot(x=col_names, y=model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)\n",
    "\n",
    "abs_differ = abs(predict - NO2_avg)\n",
    "abs_differ = pd.DataFrame(abs_differ)\n",
    "\n",
    "abs_differ = abs_differ.merge(df_tryout.geometry, how = 'left', left_index = True, right_index = True)\n",
    "abs_differ = gpd.GeoDataFrame(abs_differ, crs=\"EPSG:4326\", geometry='geometry')\n",
    "\n",
    "\n",
    "vmin, vmax = 0, 6\n",
    "fig, ax = plt.subplots(1, figsize=(30, 20))\n",
    "abs_differ.plot(column='NO2_avg', cmap='gist_yarg', linewidth=0.8,ax = ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.NO2_avg\n",
    "income = df.Income\n",
    "pob_sale = df.pob_sale\n",
    "travel_perc = df.travel_perc\n",
    "\n",
    "tot_build_perc = df.tot_build_perc\n",
    "housing_perc = df.housing_perc\n",
    "\n",
    "young_per_km2 = df.young_per_km2\n",
    "middle_per_km2 = df.middle_per_km2\n",
    "old_per_km2 = df.old_per_km2\n",
    "\n",
    "less45m2_per_km2 = df.less45m2_per_km2\n",
    "med_small_per_km2 = df['46m2_50m2_per_km2']\n",
    "large_med_per_km2 = df['61m2_90m2_per_km2']\n",
    "more90m2_per_km2 = df.more90m2_per_km2\n",
    "\n",
    "####################\n",
    "income = np.asarray(income).reshape(-1,1).astype(float)\n",
    "pob_sale = np.asarray(pob_sale).reshape(-1,1).astype(float)\n",
    "travel_perc = np.asarray(travel_perc).reshape(-1,1).astype(float)\n",
    "\n",
    "tot_build_perc = np.asarray(tot_build_perc).reshape(-1,1).astype(float)\n",
    "housing_perc = np.asarray(housing_perc).reshape(-1,1).astype(float)\n",
    "\n",
    "young_per_km2 = np.asarray(young_per_km2).reshape(-1,1).astype(float)\n",
    "middle_per_km2 = np.asarray(middle_per_km2).reshape(-1,1).astype(float)\n",
    "old_per_km2 = np.asarray(old_per_km2).reshape(-1,1).astype(float)\n",
    "\n",
    "less45m2_per_km2 = np.asarray(less45m2_per_km2).reshape(-1,1).astype(float)\n",
    "med_small_per_km2 = np.asarray(med_small_per_km2).reshape(-1,1).astype(float)\n",
    "large_med_per_km2 = np.asarray(large_med_per_km2).reshape(-1,1).astype(float)\n",
    "more90m2_per_km2 = np.asarray(more90m2_per_km2).reshape(-1,1).astype(float)\n",
    "\n",
    "######################\n",
    "y_lag = ps.weights.lag_spatial(queen_w, Y)\n",
    "income_lag = ps.weights.lag_spatial(queen_w, income)\n",
    "pob_sale_lag = ps.weights.lag_spatial(queen_w, pob_sale)\n",
    "travel_perc_lag = ps.weights.lag_spatial(queen_w, travel_perc)\n",
    "\n",
    "tot_build_perc_lag = ps.weights.lag_spatial(queen_w, tot_build_perc)\n",
    "housing_perc_lag = ps.weights.lag_spatial(queen_w, housing_perc)\n",
    "\n",
    "young_per_km2_lag = ps.weights.lag_spatial(queen_w, young_per_km2)\n",
    "middle_per_km2_lag = ps.weights.lag_spatial(queen_w, middle_per_km2)\n",
    "old_per_km2_lag = ps.weights.lag_spatial(queen_w, old_per_km2)\n",
    "\n",
    "less45m2_per_km2_lag = ps.weights.lag_spatial(queen_w, less45m2_per_km2)\n",
    "med_small_per_km2_lag = ps.weights.lag_spatial(queen_w, med_small_per_km2)\n",
    "large_med_per_km2_lag = ps.weights.lag_spatial(queen_w, large_med_per_km2)\n",
    "more90m2_per_km2_lag = ps.weights.lag_spatial(queen_w, more90m2_per_km2)\n",
    "\n",
    "\n",
    "\n",
    "lag_matrix = np.concatenate(( income_lag,  pob_sale_lag,travel_perc_lag, tot_build_perc_lag, housing_perc_lag, young_per_km2_lag, middle_per_km2_lag, old_per_km2_lag, less45m2_per_km2_lag, med_small_per_km2_lag, large_med_per_km2_lag,more90m2_per_km2_lag),axis=1)\n",
    "names= ['income_lag','pob_sale_lag','travel_perc_lag','tot_build_perc_lag','housing_perc_lag','young_per_km2_lag','middle_per_km2_lag','old_per_km2_lag','less45m2_per_km2_lag','med_small_per_km2_lag','large_med_per_km2_lag','more90m2_per_km2_lag']\n",
    "\n",
    "lag_df = pd.DataFrame(data=lag_matrix, columns= names, index = None )\n",
    "lag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "moran_Y  = Moran(Y , queen_w)\n",
    "from splot.esda import moran_scatterplot\n",
    "fig, ax = moran_scatterplot(moran_Y , aspect_equal=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_lag1 = pd.DataFrame(income_lag)\n",
    "income_lag1 = income_lag1.merge(df_tryout.geometry, how = 'left', left_index = True, right_index = True)\n",
    "income_lag1 = gpd.GeoDataFrame(income_lag1, crs=\"EPSG:4326\", geometry='geometry')\n",
    "income_lag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 3000, 12000\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(30, 20))\n",
    "\n",
    "income_lag1.plot(column=0, cmap='gist_yarg', linewidth=0.8,ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resall =pd.DataFrame()\n",
    "res_w1 =pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "\n",
    "num_trees=100\n",
    "num_features=5\n",
    "max_depth = 5\n",
    "model=RandomForestRegressor(n_estimators=num_trees, max_features=num_features,max_depth=max_depth, random_state=seed)\n",
    "model.fit(lag_matrix,Y)\n",
    "\n",
    "results_NO2_avg=cross_val_score(model, lag_matrix, Y, cv=kfold)\n",
    "\n",
    "print(f'Random Forest - Accuracy {results_NO2_avg.mean()*100:.3f}% std {results_NO2_avg.std()*100:3f}%')\n",
    "\n",
    "res_w1[\"Res\"]=results_NO2_avg\n",
    "res_w1[\"Type\"]=\"Random Forest\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,9))\n",
    "\n",
    "for name, importance in zip(names, model.feature_importances_):\n",
    "    print(f'{name:15s}  {importance:.4f}')\n",
    "\n",
    "sns.barplot(x=names, y=model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(lag_matrix)\n",
    "\n",
    "abs_diff =  abs(pred - Y)\n",
    "abs_diff = pd.DataFrame(abs_diff)\n",
    "\n",
    "abs_diff = abs_diff.merge(df_tryout.geometry, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "abs_diff = gpd.GeoDataFrame(abs_diff, crs=\"EPSG:4326\", geometry='geometry')\n",
    "\n",
    "vmin, vmax = 0, 3\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(30, 20))\n",
    "\n",
    "abs_diff.plot(column='NO2_avg', cmap='gist_yarg', linewidth=0.8,ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_matrix = np.concatenate(( income_lag,  pob_sale_lag, less45m2_per_km2_lag, med_small_per_km2, large_med_per_km2,more90m2_per_km2,young_per_km2_lag,housing_perc),axis=1)\n",
    "names= ['income_lag','pob_sale_lag','less45m2_per_km2','med_small_per_km2','large_med_per_km2','more90m2_per_km2','young_per_km2_lag','housing_perc']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_matrix1= pd.DataFrame(mix_matrix)\n",
    "mix_matrix1.columns = names\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "mask = np.zeros_like(mix_matrix1.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(mix_matrix1.corr(), mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resall =pd.DataFrame()\n",
    "res_w1 =pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "\n",
    "num_trees=100\n",
    "num_features=5\n",
    "max_depth = 5\n",
    "model1=RandomForestRegressor(n_estimators=num_trees, max_features=num_features,max_depth=max_depth, random_state=seed)\n",
    "model1.fit(mix_matrix,Y)\n",
    "\n",
    "results_NO2_avg=cross_val_score(model1, mix_matrix, Y, cv=kfold)\n",
    "\n",
    "print(f'Random Forest - Accuracy {results_NO2_avg.mean()*100:.3f}% std {results_NO2_avg.std()*100:3f}%')\n",
    "\n",
    "res_w1[\"Res\"]=results_NO2_avg\n",
    "res_w1[\"Type\"]=\"Random Forest\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_NO2_avg = Y.mean()\n",
    "print(f'Average NO2 level: {mean_NO2_avg}')\n",
    "print()\n",
    "print(f'Expected error range: [{mean_NO2_avg-(1-results_NO2_avg.mean()/100)}, {mean_NO2_avg+(1-results_NO2_avg.mean()/100)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,9))\n",
    "\n",
    "for name, importance in zip(names, model1.feature_importances_):\n",
    "    print(f'{name:15s}  {importance:.4f}')\n",
    "\n",
    "sns.barplot(x=names, y=model1.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(mix_matrix)\n",
    "\n",
    "abs_diff1 = abs(Y-pred1)/Y\n",
    "abs_diff1 = pd.DataFrame(abs_diff1)\n",
    "\n",
    "abs_diff1 = abs_diff1.merge(df_tryout.geometry, how = 'left', left_index = True, right_index = True)\n",
    "abs_diff1\n",
    "\n",
    "abs_diff1 = gpd.GeoDataFrame(abs_diff1, crs=\"EPSG:4326\", geometry='geometry')\n",
    "\n",
    "vmin, vmax = 0, 0.5\n",
    "#fig, ax = plt.subplots(1, figsize=(30, 20))\n",
    "\n",
    "#abs_diff1.plot(column='NO2_avg', cmap='gist_yarg', linewidth=0.8,ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resall =pd.DataFrame()\n",
    "res_w1 =pd.DataFrame()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "\n",
    "num_trees=100\n",
    "num_features=5\n",
    "max_depth = 5\n",
    "model12=xgb.XGBRegressor(colsample_bytree=0.4,\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=3,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=10000,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=42) \n",
    "model12.fit(mix_matrix,Y)\n",
    "\n",
    "results_NO2_avg=cross_val_score(model12, mix_matrix, Y, cv=kfold)\n",
    "\n",
    "print(f'Random Forest - Accuracy {results_NO2_avg.mean()*100:.3f}% std {results_NO2_avg.std()*100:3f}%')\n",
    "\n",
    "res_w1[\"Res\"]=results_NO2_avg\n",
    "res_w1[\"Type\"]=\"Random Forest\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,9))\n",
    "\n",
    "for name, importance in zip(names, model12.feature_importances_):\n",
    "    print(f'{name:15s}  {importance:.4f}')\n",
    "\n",
    "sns.barplot(x=names, y=model12.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model12.predict(mix_matrix)\n",
    "\n",
    "abs_diff2 = abs(Y-pred2)/Y\n",
    "abs_diff2 = pd.DataFrame(abs_diff2)\n",
    "\n",
    "abs_diff2 = abs_diff2.merge(df_tryout.geometry, how = 'left', left_index = True, right_index = True)\n",
    "abs_diff2\n",
    "\n",
    "abs_diff2 = gpd.GeoDataFrame(abs_diff2, crs=\"EPSG:4326\", geometry='geometry')\n",
    "\n",
    "#vmin, vmax = 0, 1\n",
    "#ig, ax = plt.subplots(1, figsize=(30, 20),vmin =0, vmax =  1)\n",
    "\n",
    "#abs_diff2.plot(column='NO2_avg', cmap='gist_yarg', linewidth=0.8,ax = ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff2.NO2_avg = np.clip(abs_diff2.NO2_avg, 0, 1)\n",
    "fig, ax = plt.subplots(1, figsize=(30, 20))\n",
    "abs_diff2.plot(column='NO2_avg', cmap='gist_yarg', linewidth=0.8,ax = ax, legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
